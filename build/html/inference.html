
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Inference &#8212; UQpy v3.0 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Dimension reduction" href="dimension_reduction.html" />
    <link rel="prev" title="Reliability" href="reliability.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="inference">
<span id="id1"></span><h1>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h1>
<span class="target" id="module-UQpy.Inference"></span><p>This module contains classes and functions for statistical inference from data.</p>
<p>The module currently contains the
following classes:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code>: Define a probabilistic model for Inference.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code>: Compute maximum likelihood parameter estimate.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">InfoModelSelection</span></code>: Perform model selection using information theoretic criteria.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code>: Perform Bayesian parameter estimation (estimate posterior density) via MCMC or IS.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BayesModelSelection</span></code>: Estimate model posterior probabilities.</p></li>
</ul>
<p>The goal in inference can be twofold: 1) given a model, parameterized by parameter vector <span class="math notranslate nohighlight">\(\theta\)</span>, and some data <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, learn the value of the parameter vector that best explains the data; 2) given a set of candidate models <span class="math notranslate nohighlight">\(\lbrace m_{i} \rbrace_{i=1:M}\)</span> and some data <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, learn which model best explains the data. <code class="docutils literal notranslate"><span class="pre">UQpy</span></code> currently supports the following inference algorithms for parameter estimation (see e.g. <a class="footnote-reference brackets" href="#id9" id="id2">1</a> for theory on parameter estimation in frequentist vs. Bayesian frameworks):</p>
<ul class="simple">
<li><p>Maximum Likelihood estimation,</p></li>
<li><p>Bayesian approach: estimation of posterior pdf via sampling methods (MCMC/IS).</p></li>
</ul>
<p>and the following algorithms for model selection:</p>
<ul class="simple">
<li><p>Model selection using information theoretic criteria,</p></li>
<li><p>Bayesian model class selection, i.e., estimation of model posterior probabilities.</p></li>
</ul>
<p>The capabilities of <code class="docutils literal notranslate"><span class="pre">UQpy</span></code> and associated classes are summarized in the following figure.</p>
<a class="reference internal image-reference" href="_images/Inference_schematic.png"><img alt="_images/Inference_schematic.png" class="align-left" src="_images/Inference_schematic.png" style="width: 584.8000000000001px; height: 333.6px;" /></a>
<div class="section" id="inferencemodel">
<h2>InferenceModel<a class="headerlink" href="#inferencemodel" title="Permalink to this headline">¶</a></h2>
<p>For any inference task, the user must first create, for each model studied, an instance of the class <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code> that defines the problem at hand. The following figure summarizes the four types of inference models that are supported by <code class="docutils literal notranslate"><span class="pre">UQpy</span></code>.</p>
<a class="reference internal image-reference" href="_images/Inference_models.png"><img alt="_images/Inference_models.png" class="align-left" src="_images/Inference_models.png" style="width: 617.4px; height: 371.4px;" /></a>
<div class="section" id="class-descriptions">
<h3>Class Descriptions<a class="headerlink" href="#class-descriptions" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="UQpy.Inference.InferenceModel">
<em class="property">class </em><code class="sig-prename descclassname">UQpy.Inference.</code><code class="sig-name descname">InferenceModel</code><span class="sig-paren">(</span><em class="sig-param">nparams</em>, <em class="sig-param">run_model_object=None</em>, <em class="sig-param">log_likelihood=None</em>, <em class="sig-param">dist_object=None</em>, <em class="sig-param">name=''</em>, <em class="sig-param">error_covariance=1.0</em>, <em class="sig-param">prior=None</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">**kwargs_likelihood</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#InferenceModel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.InferenceModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Define a probabilistic model for inference.</p>
<p>This class defines an inference model that will serve as input for all remaining inference classes. A model can be
defined in various ways:</p>
<ul class="simple">
<li><p>case 1a: Gaussian error model powered by RunModel, i.e., <cite>data ~ h(theta) + eps</cite>, where <cite>eps</cite> is iid Gaussian and
<cite>h</cite> consists in running RunModel. Data is a 1D ndarray in this setting.</p></li>
<li><p>case 1b: non-Gaussian error model powered by RunModel, the user must provide the likelihood function in addition
to a RunModel object. The data type is user-defined and must be consistent with the likelihood function definition</p></li>
<li><p>case 2: the likelihood function is user-defined and does not leverage RunModel. The data type must be consistent
with the likelihood function definition.</p></li>
<li><p>case 3: Learn parameters of a probability distribution pi (in dimension dim). Data is an ndarray of shape
(ndata, dim) and consists in ndata iid samples from pi. The user must define the distribution_object input. The
following lines of code show how to create an object for case 3:</p></li>
</ul>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dist</span> <span class="o">=</span> <span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_model</span> <span class="o">=</span> <span class="n">InferenceModel</span><span class="p">(</span><span class="n">nparams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">distribution_object</span><span class="o">=</span><span class="n">dist</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Input:</strong></p>
<ul>
<li><dl class="simple">
<dt><strong>nparams</strong> (<cite>int</cite>):</dt><dd><p>Number of parameters to be estimated.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>name</strong> (<cite>string</cite>):</dt><dd><p>Name of model - optional but useful in a model selection setting.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>run_model_object</strong> (object of class <code class="docutils literal notranslate"><span class="pre">RunModel</span></code>):</dt><dd><p><code class="docutils literal notranslate"><span class="pre">RunModel</span></code> class object that defines the forward model. This input is required for cases 1a and 1b.</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>log_likelihood</strong> (callable):</dt><dd><p>Function that defines the log-likelihood model, possibly in conjunction with the run_model_object (cases 1b and
2). Default is None, then a Gaussian-error model is considered (case 1a).</p>
<div class="line-block">
<div class="line">If a run_model_object is also defined (case 1b), this function is called as:</div>
<div class="line"><cite>model_outputs = run_model_object.run(samples=params).qoi_list</cite></div>
<div class="line"><cite>log_likelihood(params, model_outputs, data, **kwargs_likelihood)</cite></div>
</div>
<div class="line-block">
<div class="line">If no run_model_object is defined (case 2), this function is called as:</div>
<div class="line"><cite>log_likelihood(params, data, **kwargs_likelihood)</cite></div>
</div>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>kwargs_likelihood</strong>:</dt><dd><p>Key-word arguments transferred to the log-likelihood function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>dist_object</strong> (object of class <code class="docutils literal notranslate"><span class="pre">Distribution</span></code>):</dt><dd><p>Distribution <span class="math notranslate nohighlight">\(\pi\)</span> for which to learn parameters from iid data (case 3). When creating this
<code class="docutils literal notranslate"><span class="pre">Distribution</span></code> object, the parameters to be learnt should be set to None.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>error_covariance</strong> (<cite>ndarray</cite> or <cite>float</cite>):</dt><dd><p>Covariance for Gaussian error model (case 1a). It can be a scalar (in which case the covariance matrix is the
identity times that value), a 1d <cite>ndarray</cite> in which case the covariance is assumed to be diagonal or a full
covariance matrix (2D <cite>ndarray</cite>). Default value is 1.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>prior</strong> (object of class <code class="docutils literal notranslate"><span class="pre">Distribution</span></code>):</dt><dd><p>Prior distribution, must have a <cite>log_pdf</cite> or <cite>pdf</cite> method.</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Methods:</strong></p>
<dl class="method">
<dt id="UQpy.Inference.InferenceModel.evaluate_log_likelihood">
<code class="sig-name descname">evaluate_log_likelihood</code><span class="sig-paren">(</span><em class="sig-param">params</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#InferenceModel.evaluate_log_likelihood"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.InferenceModel.evaluate_log_likelihood" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the log likelihood <cite>log p(data|params)</cite>.</p>
<p>This method is the central piece for the Inference module, it is being called repeatedly by all other inference
classes to evaluate the likelihood of the data. The log-likelihood can be evaluated at several parameter vectors
at once, i.e., <cite>params</cite> is a <cite>ndarray</cite> of shape (nsamples, nparams). If the inference model is powered by
<code class="docutils literal notranslate"><span class="pre">RunModel</span></code> the <cite>RunModel.run</cite> method is called here, possibly leveraging its serial/parallel execution.</p>
<p><strong>Inputs:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>params</strong> (<cite>ndarray</cite>):</dt><dd><p>Parameter vector(s) at which to evaluate the likelihood function, <cite>ndarray</cite> of shape (nsamples, nparams).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>data</strong> (<cite>ndarray</cite>):</dt><dd><p>Data from which to learn. For case 1b, this should be a <cite>ndarray</cite> of shape (ndata, ). For case 3, it must
be a <cite>ndarray</cite> of shape (ndata, dimension). For other cases it must be consistent with the definition of
the log_likelihood callable input.</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Output/Returns:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt>(<cite>ndarray</cite>):</dt><dd><p>Log-likelihood evaluated at all nsamples parameter vector values, <cite>ndarray</cite> of shape (nsamples, ).</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="UQpy.Inference.InferenceModel.evaluate_log_posterior">
<code class="sig-name descname">evaluate_log_posterior</code><span class="sig-paren">(</span><em class="sig-param">params</em>, <em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#InferenceModel.evaluate_log_posterior"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.InferenceModel.evaluate_log_posterior" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the scaled log posterior <cite>log(p(data|params)p(params))</cite>.</p>
<p>This method is called by classes that perform Bayesian inference. If the <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code> object does not
possess a prior, an uninformative prior <cite>p(params)=1</cite> is assumed.</p>
<p><strong>Inputs:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>params</strong> (<cite>ndarray</cite>):</dt><dd><p>Parameter vector(s) at which to evaluate the log-posterior, <cite>ndarray</cite> of shape (nsamples, nparams).</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>data</strong> (<cite>ndarray</cite>):</dt><dd><p>Data from which to learn. See <cite>evaluate_log_likelihood</cite> method for details.</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Output/Returns:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt>(<cite>ndarray</cite>):</dt><dd><p>Log-posterior evaluated at all nsamples parameter vector values, <cite>ndarray</cite> of shape (nsamples, ).</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="parameter-estimation">
<h2>Parameter estimation<a class="headerlink" href="#parameter-estimation" title="Permalink to this headline">¶</a></h2>
<p>Parameter estimation refers to process of estimating the parameter vector of a given model. Depending on the nature of the method, parameter estimation may provide a point estimator or a probability distribution for the parameter vector. <code class="docutils literal notranslate"><span class="pre">UQpy</span></code> supports two different types of parameter estimation: Maximum Likelihood estimation through the <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class and Bayesian parameter estimation through the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> class.</p>
</div>
<div class="section" id="mlestimation">
<h2>MLEstimation<a class="headerlink" href="#mlestimation" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class evaluates the maximum likelihood estimate <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> of the model parameters, i.e.</p>
<div class="math notranslate nohighlight">
\[\hat{\theta} = \text{argmax}_{\Theta} \quad p(\mathcal{D} \vert \theta)\]</div>
<p>Note: for a Gaussian-error model of the form <span class="math notranslate nohighlight">\(\mathcal{D}=h(\theta)+\epsilon\)</span>, <span class="math notranslate nohighlight">\(\epsilon \sim N(0, \sigma)\)</span> with fixed <span class="math notranslate nohighlight">\(\sigma\)</span> and independent measurements <span class="math notranslate nohighlight">\(\mathcal{D}_{i}\)</span>, maximizing the likelihood is mathematically equivalent to minimizing the sum of squared residuals <span class="math notranslate nohighlight">\(\sum_{i} \left( \mathcal{D}_{i}-h(\theta) \right)^{2}\)</span>.</p>
<p>A numerical optimization procedure is performed to compute the MLE. By default, the <cite>minimize</cite> function of the <code class="docutils literal notranslate"><span class="pre">scipy.optimize</span></code> module is used, however other optimizers can be leveraged via the <cite>optimizer</cite> input of the  <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class.</p>
<div class="section" id="id3">
<h3>Class Descriptions<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="UQpy.Inference.MLEstimation">
<em class="property">class </em><code class="sig-prename descclassname">UQpy.Inference.</code><code class="sig-name descname">MLEstimation</code><span class="sig-paren">(</span><em class="sig-param">inference_model</em>, <em class="sig-param">data</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">iter_optim=None</em>, <em class="sig-param">x0=None</em>, <em class="sig-param">optimizer=None</em>, <em class="sig-param">**kwargs_optimizer</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#MLEstimation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.MLEstimation" title="Permalink to this definition">¶</a></dt>
<dd><p>Evaluate the maximum likelihood estimate of a model given some data.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_model</span> <span class="o">=</span> <span class="n">InferenceModel</span><span class="p">(</span><span class="n">nparams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dist_object</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ml_estimator</span> <span class="o">=</span> <span class="n">MLEstimation</span><span class="p">(</span><span class="n">inference_model</span><span class="o">=</span><span class="n">candidate_model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">iter_optim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ml_estimator</span><span class="o">.</span><span class="n">mle</span><span class="p">)</span>
<span class="go">[-0.03        0.20607442]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">ml_estimator</span><span class="o">.</span><span class="n">max_log_like</span><span class="p">)</span>
<span class="go">0.4817381371542576</span>
</pre></div>
</div>
<p><strong>Inputs:</strong></p>
<ul>
<li><dl class="simple">
<dt><strong>inference_model</strong> (object of class <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code>):</dt><dd><p>The inference model that defines the likelihood function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>data</strong> (<cite>ndarray</cite>):</dt><dd><p>Available data, <cite>ndarray</cite> of shape consistent with log likelihood function in <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code></p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>optimizer</strong> (callable):</dt><dd><p>Optimization algorithm used to compute the mle.</p>
<div class="line-block">
<div class="line">This callable takes in as first input the function to be minimized and as second input an initial guess
(<cite>ndarray</cite> of shape (n_params, )), along with optional keyword arguments if needed, i.e., it is called within
the code as:</div>
<div class="line"><cite>optimizer(func, x0, **kwargs_optimizer)</cite></div>
</div>
<p>It must return an object with attributes x (minimizer) and fun (minimum function value).</p>
<p>Default is scipy.optimize.minimize.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>kwargs_optimizer</strong>:</dt><dd><p>Key-word arguments that will be transferred to the optimizer.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>x0</strong> (<cite>ndarray</cite>):</dt><dd><p>Starting point(s) for optimization, see <cite>run_estimation</cite>. Default is None.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>iter_optim</strong> (<cite>int</cite>):</dt><dd><p>Number of iterations that the optimization is run, starting at random initial guesses. See <cite>run_estiamtion</cite>.
Default is None.</p>
</dd>
</dl>
</li>
</ul>
<p>If both <cite>x0</cite> and <cite>iter_optim</cite> are None, the object is created but the optimization procedure is not run, one must
call the run method.</p>
<p><strong>Attributes:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>mle</strong> (<cite>ndarray</cite>):</dt><dd><p>Value of parameter vector that maximizes the likelihood function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>max_log_like</strong> (<cite>float</cite>):</dt><dd><p>Value of the likelihood function at the MLE.</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Methods:</strong></p>
<dl class="method">
<dt id="UQpy.Inference.MLEstimation.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param">iter_optim=1</em>, <em class="sig-param">x0=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#MLEstimation.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.MLEstimation.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the maximum likelihood estimation procedure.</p>
<p>This function runs the optimization and updates the mle and max_log_like attributes of the class. When learning
the parameters of a distribution, if dist_object possesses an mle method this method is leveraged. If <cite>x0</cite> or
<cite>iter_optim</cite> are given when creating the MLEstimation object, this method is called directly when the object is
created.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><dl class="simple">
<dt><strong>x0</strong> (<cite>ndarray</cite>):</dt><dd><p>Initial guess(es) for optimization, ndarray of shape (nstarts, nparams) or (nparams, ), where nstarts is
the number of times the optimizer will be called. Alternatively, the user can provide input iter_optim to
randomly samples initial guess(es). The identified MLE is the one that yields the maximum log likelihood
over all calls of the optimizer.</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>iter_optim</strong> (<cite>int</cite>):</dt><dd><p>Number of iterations that the optimization is run, starting at random initial guesses. It is only used if
<cite>x0</cite> is not provided. Default is 1.</p>
<p>The random initial guesses are sampled uniformly between 0 and 1, or uniformly between user-defined bounds
if an input bounds is provided to the <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> object.</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

</dd></dl>

<p><strong>Note on subclassing MLEstimation</strong></p>
<p>More generally, the user may want to compute a parameter estimate by minimizing an error function between the data and model outputs. This can be easily done by subclassing the <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class and overwriting the method <cite>_evaluate_func_to_minimize</cite>.</p>
</div>
</div>
<div class="section" id="bayesparameterestimation">
<h2>BayesParameterEstimation<a class="headerlink" href="#bayesparameterestimation" title="Permalink to this headline">¶</a></h2>
<p>Given some data <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, a parameterized model for the data, and a prior probability density for the model parameters <span class="math notranslate nohighlight">\(p(\theta)\)</span>, the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> class is leveraged to draw samples from the posterior pdf of the model parameters using Markov Chain Monte Carlo or Importance Sampling. Via Bayes theorem, the posterior pdf is defined as follows:</p>
<div class="math notranslate nohighlight">
\[p(\theta \vert \mathcal{D}) = \frac{p(\mathcal{D} \vert \theta)p(\theta)}{p(\mathcal{D})}\]</div>
<p>Note that if no prior is defined in the model, the prior pdf is chosen as uninformative, i.e., <span class="math notranslate nohighlight">\(p(\theta) = 1\)</span> (cautionary note, this is an improper prior).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> leverages the <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> or <code class="docutils literal notranslate"><span class="pre">IS</span></code> classes of the <code class="docutils literal notranslate"><span class="pre">SampleMethods</span></code> module of <code class="docutils literal notranslate"><span class="pre">UQpy</span></code>. When creating a <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> object, an object of class <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> or <code class="docutils literal notranslate"><span class="pre">IS</span></code> is created and saved as an attribute <cite>sampler</cite>. The <code class="docutils literal notranslate"><span class="pre">run</span></code> method of the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> class then calls the <code class="docutils literal notranslate"><span class="pre">run</span></code> method of that sampler, thus the user can add samples as they wish by calling the <code class="docutils literal notranslate"><span class="pre">run</span></code> method several times.</p>
<div class="section" id="id4">
<h3>Class Descriptions<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="UQpy.Inference.BayesParameterEstimation">
<em class="property">class </em><code class="sig-prename descclassname">UQpy.Inference.</code><code class="sig-name descname">BayesParameterEstimation</code><span class="sig-paren">(</span><em class="sig-param">inference_model</em>, <em class="sig-param">data</em>, <em class="sig-param">sampling_class=None</em>, <em class="sig-param">nsamples=None</em>, <em class="sig-param">nsamples_per_chain=None</em>, <em class="sig-param">nchains=1</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">**kwargs_sampler</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#BayesParameterEstimation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.BayesParameterEstimation" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate the parameter posterior density given some data.</p>
<p>This class generates samples from the parameter posterior distribution, using MCMC or IS. It leverages the MCMC and
IS classes from the SampleMethods module.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">UQpy.Distributions</span> <span class="k">import</span> <span class="n">JointInd</span><span class="p">,</span> <span class="n">Uniform</span><span class="p">,</span> <span class="n">Lognormal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prior</span> <span class="o">=</span> <span class="n">JointInd</span><span class="p">(</span><span class="n">marginals</span><span class="o">=</span><span class="p">[</span><span class="n">Uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">15</span><span class="p">),</span> <span class="n">Lognormal</span><span class="p">(</span><span class="n">s</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">0.</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">1.</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">candidate_model</span> <span class="o">=</span> <span class="n">InferenceModel</span><span class="p">(</span><span class="n">dist_object</span><span class="o">=</span><span class="n">Normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">nparams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">UQpy.SampleMethods</span> <span class="k">import</span> <span class="n">MH</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">])</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bayes_estimator</span> <span class="o">=</span> <span class="n">BayesParameterEstimation</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">inference_model</span><span class="o">=</span><span class="n">candidate_model</span><span class="p">,</span> <span class="n">sampling_class</span><span class="o">=</span><span class="n">MH</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bayes_estimator</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">nsamples</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">bayes_estimator</span><span class="o">.</span><span class="n">sampler</span><span class="o">.</span><span class="n">samples</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="go">(5, 2)</span>
</pre></div>
</div>
<p><strong>Inputs:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>model</strong> (object of class <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code>):</dt><dd><p>The inference model that defines the likelihood function.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>data</strong> (<cite>ndarray</cite>):</dt><dd><p>Available data, <cite>ndarray</cite> of shape consistent with log-likelihood function in InferenceModel</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>sampling_class</strong> (class instance):</dt><dd><p>Class instance, must be a subclass of <code class="docutils literal notranslate"><span class="pre">MCMC</span></code> or <code class="docutils literal notranslate"><span class="pre">IS</span></code>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>kwargs_sampler</strong>:</dt><dd><p>Key-word arguments of the sampling class.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>nchains</strong>:</dt><dd><p>Number of chains in MCMC, will be used to sample seed from prior if seed is not provided. Default is 1.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>nsamples</strong> (<cite>int</cite>):</dt><dd><p>Number of samples used in MCMC/IS, see <cite>run</cite> method.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>samples_per_chain</strong> (<cite>int</cite>):</dt><dd><p>Number of samples per chain used in MCMC, see <cite>run</cite> method.</p>
</dd>
</dl>
</li>
</ul>
<p>If both <cite>nsamples</cite> and <cite>nsamples_per_chain</cite> are None, the object is created but the sampling procedure is not run,
one must call the run method.</p>
<p><strong>Attributes:</strong></p>
<ul>
<li><dl>
<dt><strong>sampler</strong> (object of sampling_class):</dt><dd><p>Sampling method object, contains e.g. the posterior samples.</p>
<p>This object is created along with the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> object, and its <cite>run</cite> method is called
whenever the <cite>run</cite> method of the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> is called.</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Methods:</strong></p>
<dl class="method">
<dt id="UQpy.Inference.BayesParameterEstimation.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param">nsamples=None</em>, <em class="sig-param">nsamples_per_chain=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#BayesParameterEstimation.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.BayesParameterEstimation.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the Bayesian inference procedure, i.e., sample from the parameter posterior distribution.</p>
<p>This function calls the <cite>run</cite> method of the <cite>sampler</cite> attribute to generate samples from the parameter posterior
distribution.</p>
<p><strong>Inputs:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>nsamples</strong> (<cite>int</cite>):</dt><dd><p>Number of samples used in MCMC/IS</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>samples_per_chain</strong> (<cite>int</cite>):</dt><dd><p>Number of samples per chain used in MCMC</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="model-selection">
<h2>Model Selection<a class="headerlink" href="#model-selection" title="Permalink to this headline">¶</a></h2>
<p>Model selection refers to the task of selecting a statistical model from a set of candidate models, given some data. A good model is one that is capable of explaining the data well. Given models of the same explanatory power, the simplest model should be chosen (Occam’s razor).</p>
</div>
<div class="section" id="infomodelselection">
<h2>InfoModelSelection<a class="headerlink" href="#infomodelselection" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">InfoModelSelection</span></code> class employs information-theoretic criteria for model selection. Several simple information theoretic criteria can be used to compute a model’s quality and perform model selection <a class="footnote-reference brackets" href="#id10" id="id5">2</a>. <code class="docutils literal notranslate"><span class="pre">UQpy</span></code> implements three criteria:</p>
<ul class="simple">
<li><p>Bayesian information criterion,  <span class="math notranslate nohighlight">\(BIC = \ln(n) k - 2 \ln(\hat{L})\)</span></p></li>
<li><p>Akaike information criterion, <span class="math notranslate nohighlight">\(AIC = 2 k - 2 \ln (\hat{L})\)</span></p></li>
<li><p>Corrected formula for AIC (AICc), for small data sets , <span class="math notranslate nohighlight">\(AICc = AIC + \frac{2k(k+1)}{n-k-1}\)</span></p></li>
</ul>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is the number of parameters characterizing the model, <span class="math notranslate nohighlight">\(\hat{L}\)</span> is the maximum value of the likelihood function, and <span class="math notranslate nohighlight">\(n\)</span> is the number of data points. The best model is the one that minimizes the criterion, which is a combination of a model fit term (find the model that minimizes the negative log likelihood) and a penalty term that increases as the number of model parameters (model complexity) increases.</p>
<p>A probability can be defined for each model as <span class="math notranslate nohighlight">\(P(m_{i}) \propto \exp\left(  -\frac{\text{criterion}}{2} \right)\)</span>.</p>
<div class="section" id="id6">
<h3>Class Descriptions<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="UQpy.Inference.InfoModelSelection">
<em class="property">class </em><code class="sig-prename descclassname">UQpy.Inference.</code><code class="sig-name descname">InfoModelSelection</code><span class="sig-paren">(</span><em class="sig-param">candidate_models</em>, <em class="sig-param">data</em>, <em class="sig-param">criterion='AIC'</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">iter_optim=None</em>, <em class="sig-param">x0=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#InfoModelSelection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.InfoModelSelection" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform model selection using information theoretic criteria.</p>
<p>Supported criteria are BIC, AIC (default), AICc. This class leverages the <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class for maximum
likelihood estimation, thus inputs to <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> can also be provided to <code class="docutils literal notranslate"><span class="pre">InfoModelSelection</span></code>, as lists of
length equal to the number of models.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">UQpy.Distributions</span> <span class="k">import</span> <span class="n">Gamma</span><span class="p">,</span> <span class="n">Exponential</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m0</span> <span class="o">=</span> <span class="n">InferenceModel</span><span class="p">(</span><span class="n">dist_object</span><span class="o">=</span><span class="n">Gamma</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">nparams</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;gamma&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m1</span> <span class="o">=</span> <span class="n">InferenceModel</span><span class="p">(</span><span class="n">dist_object</span><span class="o">=</span><span class="n">Exponential</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="kc">None</span><span class="p">),</span> <span class="n">nparams</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;exponential&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.98948677</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.68020571</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.45840788</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">selector</span> <span class="o">=</span> <span class="n">InfoModelSelection</span><span class="p">(</span><span class="n">candidate_models</span><span class="o">=</span><span class="p">[</span><span class="n">m0</span><span class="p">,</span> <span class="n">m1</span><span class="p">],</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s1">&#39;BIC&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">selector</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">iter_optim</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">ml_estimators</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">mle</span><span class="p">)</span>
<span class="go">[ 3.95134934e+02 -1.01996273e+01  3.01344306e-02]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">selector</span><span class="o">.</span><span class="n">ml_estimators</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">mle</span><span class="p">)</span>
<span class="go">[0.98948677 0.71988002]</span>
</pre></div>
</div>
<p><strong>Inputs:</strong></p>
<ul>
<li><dl class="simple">
<dt><strong>candidate_models</strong> (<cite>list</cite> of <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code> objects):</dt><dd><p>Candidate models</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>data</strong> (<cite>ndarray</cite>):</dt><dd><p>Available data</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>criterion</strong> (<cite>str</cite>):</dt><dd><p>Criterion to be used (AIC, BIC, AICc). Default is ‘AIC’</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>kwargs</strong>:</dt><dd><p>Additional key-word inputs to the maximum likelihood estimators.</p>
<p>Keys must refer to input names to the <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class, and values must be lists of length nmodels,
ordered in the same way as input <cite>candidate_models</cite>. For example, setting
<cite>kwargs={`method’: [`Nelder-Mead’, `Powell’]}</cite> means that the Nelder-Mead minimization algorithm will be used for
ML estimation of the first candidate model, while the Powell method will be used for the second candidate model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>x0</strong> (<cite>list</cite> of <cite>ndarrays</cite>):</dt><dd><p>Starting points for optimization - see MLEstimation</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>iter_optim</strong> (<cite>list</cite> of <cite>int</cite>):</dt><dd><p>Number of iterations for the maximization procedure - see MLEstimation</p>
</dd>
</dl>
</li>
</ul>
<p>If <cite>x0</cite> and <cite>iter_optim</cite> are both None, the object is created but the model selection procedure is not run, one
must then call the <cite>run</cite> method.</p>
<p><strong>Attributes:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>ml_estimators</strong> (<cite>list</cite> of <cite>MLEstimation</cite> objects):</dt><dd><p>MLEstimation results for each model (contains e.g. fitted parameters)</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>criterion_values</strong> (<cite>list</cite> of <cite>floats</cite>):</dt><dd><p>Value of the criterion for all models.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>penalty_terms</strong> (<cite>list</cite> of <cite>floats</cite>):</dt><dd><p>Value of the penalty term for all models. Data fit term is then criterion_value - penalty_term.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>probabilities</strong> (<cite>list</cite> of <cite>floats</cite>):</dt><dd><p>Value of the model probabilities, computed as <cite>P = exp(-criterion/2)</cite>.</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Methods:</strong></p>
<dl class="method">
<dt id="UQpy.Inference.InfoModelSelection.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param">iter_optim=1</em>, <em class="sig-param">x0=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#InfoModelSelection.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.InfoModelSelection.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the model selection procedure, i.e. compute criterion value for all models.</p>
<p>This function calls the <cite>run</cite> method of the MLEstimation object for each model to compute the maximum
log-likelihood, then computes the criterion value and probability for each model.</p>
<p><strong>Inputs:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>x0</strong> (<cite>list</cite> of <cite>ndarrays</cite>):</dt><dd><p>Starting point(s) for optimization for all models. Default is None. If not provided, see <cite>iter_optim</cite>. See
<code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>iter_optim</strong> (<cite>int</cite> or <cite>list</cite> of <cite>ints</cite>):</dt><dd><p>Number of iterations that the optimization is run, starting at random initial guesses. It is only used if
<cite>x0</cite> is not provided. Default is 1. See <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class.</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="UQpy.Inference.InfoModelSelection.sort_models">
<code class="sig-name descname">sort_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#InfoModelSelection.sort_models"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.InfoModelSelection.sort_models" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort models in descending order of model probability (increasing order of criterion value).</p>
<p>This function sorts - in place - the attribute lists <cite>candidate_models, ml_estimators, criterion_values,
penalty_terms</cite> and <cite>probabilities</cite> so that they are sorted from most probable to least probable model. It is a
stand-alone function that is provided to help the user to easily visualize which model is the best.</p>
<p>No inputs/outputs.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="bayesmodelselection">
<h2>BayesModelSelection<a class="headerlink" href="#bayesmodelselection" title="Permalink to this headline">¶</a></h2>
<p>In the Bayesian approach to model selection, the posterior probability of each model is computed as</p>
<div class="math notranslate nohighlight">
\[P(m_{i} \vert \mathcal{D}) = \frac{p(\mathcal{D} \vert m_{i})P(m_{i})}{\sum_{j} p(\mathcal{D} \vert m_{j})P(m_{j})}\]</div>
<p>where the evidence (also called marginal likelihood) <span class="math notranslate nohighlight">\(p(\mathcal{D} \vert m_{i})\)</span> involves an integration over the parameter space:</p>
<div class="math notranslate nohighlight">
\[p(\mathcal{D} \vert m_{i}) = \int_{\Theta} p(\mathcal{D} \vert m_{i}, \theta) p(\theta \vert m_{i}) d\theta\]</div>
<p>Currently, calculation of the evidence is performed using the method of the harmonic mean <a class="footnote-reference brackets" href="#id11" id="id7">3</a>:</p>
<div class="math notranslate nohighlight">
\[p(\mathcal{D} \vert m_{i}) = \left[ \frac{1}{B} \sum_{b=1}^{B} \frac{1}{p(\mathcal{D} \vert m_{i}, \theta_{b})} \right]^{-1}\]</div>
<p>where <span class="math notranslate nohighlight">\(\theta_{1,\cdots,B}\)</span> are samples from the posterior pdf of <span class="math notranslate nohighlight">\(\theta\)</span>. In UQpy, these samples are obtained via the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> class. However, note that this method is known to yield evidence estimates with large variance. Future releases of <code class="docutils literal notranslate"><span class="pre">UQpy</span></code> will include more robust methods for computation of model evidences. Also, it is known that results of such Bayesian model selection procedure usually highly depends on the choice of prior for the parameters of the competing models, thus the user should carefully define such priors when creating instances of the <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code> class.</p>
<div class="section" id="id8">
<h3>Class Descriptions<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="UQpy.Inference.BayesModelSelection">
<em class="property">class </em><code class="sig-prename descclassname">UQpy.Inference.</code><code class="sig-name descname">BayesModelSelection</code><span class="sig-paren">(</span><em class="sig-param">candidate_models</em>, <em class="sig-param">data</em>, <em class="sig-param">prior_probabilities=None</em>, <em class="sig-param">method_evidence_computation='harmonic_mean'</em>, <em class="sig-param">verbose=False</em>, <em class="sig-param">nsamples=None</em>, <em class="sig-param">nsamples_per_chain=None</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#BayesModelSelection"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.BayesModelSelection" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform model selection via Bayesian inference, i.e., compute model posterior probabilities given data.</p>
<p>This class leverages the BayesParameterEstimation class to get samples from the parameter posterior densities. These
samples are then used to compute the model evidence <cite>p(data|model)</cite> for all models and the model posterior
probabilities.</p>
<p><strong>References:</strong></p>
<ol class="arabic simple">
<li><p>A.E. Raftery, M.A. Newton, J.M. Satagopan, and P.N. Krivitsky. “Estimating the integrated likelihood via
posterior simulation using the harmonic mean identity”. In Bayesian Statistics 8, pages 1–45, 2007.</p></li>
</ol>
<p><strong>Inputs:</strong></p>
<ul>
<li><dl class="simple">
<dt><strong>candidate_models</strong> (<cite>list</cite> of <code class="docutils literal notranslate"><span class="pre">InferenceModel</span></code> objects):</dt><dd><p>Candidate models</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>data</strong> (<cite>ndarray</cite>):</dt><dd><p>Available data</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>prior_probabilities</strong> (<cite>list</cite> of <cite>floats</cite>):</dt><dd><p>Prior probabilities of each model, default is [1/nmodels, ] * nmodels</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>method_evidence_computation</strong> (<cite>str</cite>):</dt><dd><p>as of v3, only the harmonic mean method is supported</p>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>kwargs</strong>:</dt><dd><p>Key-word inputs to the <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> class, for each model.</p>
<p>Keys must refer to names of inputs to the <code class="docutils literal notranslate"><span class="pre">MLEstimation</span></code> class, and values should be lists of length nmodels,
ordered in the same way as input candidate_models. For example, setting
<cite>kwargs={`sampling_class’: [MH, Stretch]}</cite> means that the MH algorithm will be used for sampling from the
parameter posterior pdf of the 1st candidate model, while the Stretch algorithm will be used for the 2nd model.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>nsamples</strong> (<cite>list</cite> of <cite>int</cite>):</dt><dd><p>Number of samples used in MCMC/IS, for each model</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>samples_per_chain</strong> (<cite>list</cite> of <cite>int</cite>):</dt><dd><p>Number of samples per chain used in MCMC, for each model</p>
</dd>
</dl>
</li>
</ul>
<p>If <cite>nsamples</cite> and <cite>nsamples_per_chain</cite> are both None, the object is created but the model selection procedure is not
run, one must then call the <cite>run</cite> method.</p>
<p><strong>Attributes:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>bayes_estimators</strong> (<cite>list</cite> of <code class="docutils literal notranslate"><span class="pre">BayesParameterEstimation</span></code> objects):</dt><dd><p>Results of the Bayesian parameter estimation</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>self.evidences</strong> (<cite>list</cite> of <cite>floats</cite>):</dt><dd><p>Value of the evidence for all models</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>probabilities</strong> (<cite>list</cite> of <cite>floats</cite>):</dt><dd><p>Posterior probability for all models</p>
</dd>
</dl>
</li>
</ul>
<p><strong>Methods:</strong></p>
<dl class="method">
<dt id="UQpy.Inference.BayesModelSelection.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param">nsamples=None</em>, <em class="sig-param">nsamples_per_chain=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#BayesModelSelection.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.BayesModelSelection.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run the Bayesian model selection procedure, i.e., compute model posterior probabilities.</p>
<p>This function calls the run_estimation method of the BayesParameterEstimation object for each model to sample
from the parameter posterior probability, then computes the model evidence and model posterior probability.
This function updates attributes bayes_estimators, evidences and probabilities. If nsamples or
nsamples_per_chain are given when creating the object, this method is called directly when the object is
created. It can also be called separately.</p>
<p><strong>Inputs:</strong></p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>nsamples</strong> (<cite>list</cite> of <cite>int</cite>):</dt><dd><p>Number of samples used in MCMC/IS, for each model</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>samples_per_chain</strong> (<cite>list</cite> of <cite>int</cite>):</dt><dd><p>Number of samples per chain used in MCMC, for each model</p>
</dd>
</dl>
</li>
</ul>
</dd></dl>

<dl class="method">
<dt id="UQpy.Inference.BayesModelSelection.sort_models">
<code class="sig-name descname">sort_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/UQpy/Inference.html#BayesModelSelection.sort_models"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#UQpy.Inference.BayesModelSelection.sort_models" title="Permalink to this definition">¶</a></dt>
<dd><p>Sort models in descending order of model probability (increasing order of criterion value).</p>
<p>This function sorts - in place - the attribute lists candidate_models, prior_probabilities, probabilities and
evidences so that they are sorted from most probable to least probable model. It is a stand-alone function that
is provided to help the user to easily visualize which model is the best.</p>
<p>No inputs/outputs.</p>
</dd></dl>

</dd></dl>

<dl class="footnote brackets">
<dt class="label" id="id9"><span class="brackets"><a class="fn-backref" href="#id2">1</a></span></dt>
<dd><p>R.C. Smith, “Uncertainty Quantification - Theory, Implementation and Applications”, CS&amp;E, 2014</p>
</dd>
<dt class="label" id="id10"><span class="brackets"><a class="fn-backref" href="#id5">2</a></span></dt>
<dd><p>Burnham, K. P. and Anderson, D. R., “Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach”, Springer-Verlag, 2002</p>
</dd>
<dt class="label" id="id11"><span class="brackets"><a class="fn-backref" href="#id7">3</a></span></dt>
<dd><p>A.E. Raftery, M.A. Newton, J.M. Satagopan and P.N. Krivitsky, “Estimating the Integrated Likelihood via Posterior Simulation Using the Harmonic Mean Identity”, Bayesian Statistics 8, 2007</p>
</dd>
</dl>
<div class="toctree-wrapper compound">
</div>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.jpg" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">Uncertainty quantification with Python </p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=SURG&repo=UQpy&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="runmodel.html">RunModel</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="samplemethods.html">SampleMethods</a></li>
<li class="toctree-l1"><a class="reference internal" href="transformations.html">Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="stochastic_process.html">StochasticProcess</a></li>
<li class="toctree-l1"><a class="reference internal" href="surrogates.html">Surrogates</a></li>
<li class="toctree-l1"><a class="reference internal" href="reliability.html">Reliability</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#inferencemodel">InferenceModel</a></li>
<li class="toctree-l2"><a class="reference internal" href="#parameter-estimation">Parameter estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#mlestimation">MLEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bayesparameterestimation">BayesParameterEstimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#model-selection">Model Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#infomodelselection">InfoModelSelection</a></li>
<li class="toctree-l2"><a class="reference internal" href="#bayesmodelselection">BayesModelSelection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="dimension_reduction.html">Dimension reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="utilities.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="news.html">News</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="reliability.html" title="previous chapter">Reliability</a></li>
      <li>Next: <a href="dimension_reduction.html" title="next chapter">Dimension reduction</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, SURG, JHU.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/inference.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/SURG/UQpy" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>